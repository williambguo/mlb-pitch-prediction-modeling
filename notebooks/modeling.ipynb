{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re \n",
    "import ast \n",
    "import json \n",
    "import pickle \n",
    "from collections import Counter \n",
    "import datetime as dt\n",
    "import pybaseball\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pybaseball import pitching_stats_bref\n",
    "from pybaseball import statcast\n",
    "from pybaseball import statcast_pitcher\n",
    "from pybaseball import playerid_lookup\n",
    "from pybaseball import playerid_reverse_lookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost\n",
    "- Random Forest\n",
    "- RNN (LSTM or GRU or both)\n",
    "\n",
    "RNN will likely take too long depending on how the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/final/pitch_by_pitch_2023_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['game_type', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment', 'count', 'game_pitcher_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prev_pitch_type'] = data['prev_pitch_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prev_pitch_type'] = data['prev_pitch_type'].replace('nan', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where prev_pitch_type is UN\n",
    "data = data[data.prev_pitch_type != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pitch_type\n",
       "Fastball         286240\n",
       "Breaking Ball    150978\n",
       "Off-Speed         55266\n",
       "Specialty            66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pitch_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prev_pitch_type\n",
       "Fastball         283970\n",
       "Breaking Ball    152355\n",
       "Off-Speed         56159\n",
       "Specialty            66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prev_pitch_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pitch_type'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "\n",
    "    data.drop(columns=['game_type', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment', 'count', 'game_pitcher_id'], inplace=True)\n",
    "    \n",
    "    data['prev_pitch_type'] = data['prev_pitch_type'].replace('nan', 'Unknown')\n",
    "    data = data[data.prev_pitch_type != 'Unknown']\n",
    "    \n",
    "    data['pitch_type'] = data['pitch_type'].astype(str)\n",
    "    data['prev_pitch_type'] = data['prev_pitch_type'].astype(str)\n",
    "\n",
    "    data = data[data.pitch_type != 'Specialty']\n",
    "    data = data[data.prev_pitch_type != 'Specialty']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('../data/final/five_2023_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(columns=['game_type', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment', 'count', 'game_pitcher_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['prev_pitch_type'] = data2['prev_pitch_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['pitch_type'] = data2['pitch_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['prev_pitch_type'] = data2['prev_pitch_type'].replace('nan', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where prev_pitch_type is UN\n",
    "data2 = data2[data2.prev_pitch_type != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Specialty from both pitch_type and prev_pitch_type\n",
    "data2 = data2[data2.pitch_type != 'Specialty']\n",
    "data2 = data2[data2.prev_pitch_type != 'Specialty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pitch_type\n",
       "PFastball        162370\n",
       "Breaking Ball    150978\n",
       "MFastball        123870\n",
       "Off-Speed         55266\n",
       "Specialty            66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['pitch_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prev_pitch_type\n",
       "PFastball        160349\n",
       "Breaking Ball    152355\n",
       "MFastball        123621\n",
       "Off-Speed         56159\n",
       "Specialty            66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['prev_pitch_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_data, pitch_count_cutoff=1000):\n",
    "    '''\n",
    "    Function to train and test models for pitch prediction for individual pitchers\n",
    "    \n",
    "    train_data: a cleaned data frame\n",
    "    pitch_count_cutoff: a minimum number of pitches thrown  \n",
    "    \n",
    "    returns a pickled file for each pitcher that contains the model and some metadata for that pitcher\n",
    "    '''\n",
    "\n",
    "    # build a dict with pitch_id as key and total pitch count as value\n",
    "    pitcher_count_dict = dict(Counter(train_data['pitcher']))\n",
    "\n",
    "    # drop pitchers that don't have enough pitches to build a reliable model\n",
    "    pitcher_count_dict = {k:v for k, v in pitcher_count_dict.items() if v > pitch_count_cutoff}\n",
    "\n",
    "    # list of pitchers\n",
    "    pitcher_list = pitcher_count_dict.keys()\n",
    "    print(f\"Number of pitchers that make the cut: {len(pitcher_count_dict)}\")\n",
    "\n",
    "    # loop through the list of pitchers and train models\n",
    "    accuracy_list = []\n",
    "    naive_accuracy_list = []\n",
    "    num_skipped = 0\n",
    "    for i, pitcher in enumerate(pitcher_list):\n",
    "\n",
    "        # Start timer\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        df_pitcher = train_data[train_data['pitcher'] == pitcher].copy()\n",
    "        df_pitcher.drop('pitcher', axis=1, inplace=True)\n",
    "\n",
    "        # Get unique pitch types for the pitcher\n",
    "        pitch_types = list(set(df_pitcher['prev_pitch_type'].unique()) | set(df_pitcher['pitch_type'].unique()))\n",
    "        pitch_map = {pitch_types[i]: i for i in range(len(pitch_types))}\n",
    "        pitch_unmap = {v: k for k, v in pitch_map.items()}\n",
    "\n",
    "        # Map pitch types to integers\n",
    "        df_pitcher['pitch_type'] = df_pitcher['pitch_type'].map(pitch_map)\n",
    "        df_pitcher['prev_pitch_type'] = df_pitcher['prev_pitch_type'].map(pitch_map)\n",
    "\n",
    "        # Features and target\n",
    "        X = df_pitcher.drop('pitch_type', axis=1)\n",
    "        y = df_pitcher['pitch_type']\n",
    "\n",
    "        # Train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4256)\n",
    "\n",
    "        # Determine the classification type\n",
    "        num_classes = len(pitch_types)\n",
    "        if num_classes == 2:\n",
    "            objective = 'binary:logistic'\n",
    "        else:\n",
    "            objective = 'multi:softmax'\n",
    "\n",
    "        # XGBoost parameters\n",
    "        xgb_params = {\"max_depth\": (2, 5, 20),\n",
    "                  \"learning_rate\": (0.01, 0.1, 0.4)}\n",
    "\n",
    "        # GridSearchCV with appropriate objective\n",
    "        xgb_opt = GridSearchCV(\n",
    "            XGBClassifier(objective=objective, num_class=num_classes if num_classes > 2 else None),\n",
    "            param_grid=xgb_params,\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        xgb_opt.fit(X_train, y_train)\n",
    "        y_pred = xgb_opt.predict(X_test)\n",
    "\n",
    "        # Compute accuracies\n",
    "        accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        # Compute naive accuracy\n",
    "        pitch_type_counts = Counter(y_train)\n",
    "        naive_accuracy = round(max(pitch_type_counts.values()) / sum(pitch_type_counts.values()) * 100, 1)\n",
    "        naive_accuracy_list.append(naive_accuracy)\n",
    "\n",
    "        # Print progress for every 10th pitcher\n",
    "        if i % 10 == 0:\n",
    "            print(f\"\\nPitcher ID: {pitcher}\")\n",
    "            print(f\"Pitch Types: {pitch_map}\")\n",
    "            print(f\"Objective: {objective}\")\n",
    "            print(f\"Train Size: {X_train.shape[0]}, Test Size: {X_test.shape[0]}\")\n",
    "            print(f\"Best Params: {xgb_opt.best_params_}\")\n",
    "            print(f\"Naive Accuracy: {naive_accuracy}\")\n",
    "            print(f\"XGBoost Accuracy: {accuracy}\")\n",
    "            print(f\"Training Time: {dt.datetime.now() - start}\")\n",
    "\n",
    "        # Save the model and metadata\n",
    "        model_out = {\n",
    "            \"pitcherID\": pitcher,\n",
    "            \"pitch_map\": pitch_map,\n",
    "            \"pitch_unmap\": pitch_unmap,\n",
    "            \"model\": xgb_opt,\n",
    "            \"model_accuracy\": accuracy\n",
    "        }\n",
    "        fpath = f\"../data/pitcher_models/{pitcher}.pkl\"\n",
    "        with open(fpath, 'wb') as fobj:\n",
    "            pickle.dump(model_out, fobj)\n",
    "           \n",
    "    # return the accuracy lists so we can perform assessment \n",
    "    return accuracy_list, naive_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_models(train_data, pitch_count_cutoff=1000):\n",
    "    '''\n",
    "    Function to train and test models for pitch prediction for individual pitchers\n",
    "    \n",
    "    train_data: a cleaned data frame\n",
    "    pitch_count_cutoff: a minimum number of pitches thrown  \n",
    "    \n",
    "    returns a pickled file for each pitcher that contains the model and some metadata for that pitcher\n",
    "    '''\n",
    "\n",
    "    # build a dict with pitch_id as key and total pitch count as value\n",
    "    pitcher_count_dict = dict(Counter(train_data['pitcher']))\n",
    "\n",
    "    # drop pitchers that don't have enough pitches to build a reliable model\n",
    "    pitcher_count_dict = {k:v for k, v in pitcher_count_dict.items() if v > pitch_count_cutoff}\n",
    "\n",
    "    # list of pitchers\n",
    "    pitcher_list = pitcher_count_dict.keys()\n",
    "    print(f\"Number of pitchers that make the cut: {len(pitcher_count_dict)}\")\n",
    "\n",
    "    # loop through the list of pitchers and train models\n",
    "    accuracy_list = []\n",
    "    naive_accuracy_list = []\n",
    "    num_skipped = 0\n",
    "    for i, pitcher in enumerate(pitcher_list):\n",
    "\n",
    "        # start a timer\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        df_pitcher = train_data[train_data['pitcher'] == pitcher]\n",
    "        df_pitcher.drop('pitcher', axis=1, inplace=True)\n",
    "\n",
    "        # get a unique list of the pitcher's pitches\n",
    "        pitch_types = list(set(list(df_pitcher['prev_pitch_type'].unique()) + list(df_pitcher['pitch_type'].unique())))\n",
    "        pitch_type_counts = Counter(df_pitcher['prev_pitch_type'])\n",
    "\n",
    "        # build maps for pitches to ints and ints back to pitches\n",
    "        pitch_map = {pitch_types[i]: i for i in range(len(pitch_types))}\n",
    "        pitch_unmap = {v: k for k, v in pitch_map.items()}\n",
    "\n",
    "        # map pitch types to ints\n",
    "        df_pitcher['pitch_type'] = df_pitcher['pitch_type'].apply(lambda x: pitch_map[x])\n",
    "        df_pitcher['prev_pitch_type'] = df_pitcher['prev_pitch_type'].apply(lambda x: pitch_map[x])\n",
    "\n",
    "        # split the dataframe into a feature set and an outcome column\n",
    "        X = df_pitcher.drop('pitch_type', axis=1)\n",
    "        y = df_pitcher['pitch_type']\n",
    "\n",
    "        # split the data into train/test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \"\"\"\n",
    "        if len(np.unique(y_train)) > len(np.unique(y_test)):\n",
    "            unique_classes = len(y_train.unique())\n",
    "        else:\n",
    "            unique_classes = len(y_test.unique())\n",
    "        \n",
    "        if len(np.unique(y_train)) > len(np.unique(y_test)):\n",
    "            # Get all unique classes from y_train\n",
    "            all_classes = np.unique(y_train)\n",
    "\n",
    "            # Align the test labels with the training classes\n",
    "            y_test = pd.Categorical(y_test, categories=all_classes).codes\n",
    "        else:\n",
    "            # Get all unique classes from y_test\n",
    "            all_classes = np.unique(y_test)\n",
    "\n",
    "            # Align the training labels with the test classes\n",
    "            y_train = pd.Categorical(y_train, categories=all_classes).codes\n",
    "        \"\"\"\n",
    "        # ----------------------\n",
    "        # train an XGBoost model\n",
    "        # ----------------------\n",
    "\n",
    "        # small set of hyperparameters to optimize over\n",
    "        xgb_params = {\"max_depth\": (2, 5, 20),\n",
    "                      \"learning_rate\": (0.01, 0.1, 0.4)}\n",
    "        \n",
    "        # perform the paramater grid search using 5-fold cross validation\n",
    "        xgb_opt = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=len(pitch_type_counts)), \n",
    "                               param_grid=xgb_params, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "        # perform fit and make predictions\n",
    "        xgb_opt.fit(X_train, y_train)\n",
    "        y_pred = xgb_opt.predict(X_test)\n",
    "        y_prob = xgb_opt.predict_proba(X_test)\n",
    "\n",
    "        # compute accuracy and store in a list for analyzing results later\n",
    "        accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        # get and store the naive accuracy (accuracy from just predicting the most thrown pitch)\n",
    "        naive_accuracy = round(max(pitch_type_counts.values()) / sum(pitch_type_counts.values()) * 100., 1)\n",
    "        naive_accuracy_list.append(naive_accuracy)\n",
    "\n",
    "        # print some input/results for every 10th pitcher\n",
    "        if i % 10 == 0:\n",
    "            print()\n",
    "            print(f\"Pitcher ID: {pitcher}\")\n",
    "            print(f\"Pitcher's pitch map: {pitch_map}\")\n",
    "            print(f\"Pitcher's pitch counter: {dict(pitch_type_counts)}\")\n",
    "            print(f\"Number of data points in training: {X_train.shape[0]}\")\n",
    "            print(f\"Number of data points in testing: {X_test.shape[0]}\")\n",
    "            print(f\"Best params: {xgb_opt.best_params_}\")\n",
    "            print(f\"Total training time: {dt.datetime.now()-start}\")\n",
    "            print(f\"Naive accuracy: {naive_accuracy}\")\n",
    "            print(f\"XGBooost accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "        # ----------------------------------------------------------\n",
    "        # write out the pitchers model and metadata to a pickle file\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "        # things to store in the pitcher's model file:\n",
    "        #  1) the map and unmap for pitches (used for data clean-up in the prediction process)\n",
    "        #  2) trained model (used to make prediction)\n",
    "        #  3) accuracy on the test data (to include with pitch predictions so user can see how confident the model is)\n",
    "        model_out = {\n",
    "            \"pitcherID\": pitcher,\n",
    "            \"pitch_map\": pitch_map,\n",
    "            \"pitch_unmap\": pitch_unmap,\n",
    "            \"model\": xgb_opt,\n",
    "            \"model_accuracy\": accuracy\n",
    "        }\n",
    "\n",
    "        # pickle up the pitcher's model file\n",
    "        fpath = \"../data/pitcher_models/\" + str(pitcher) + \".pkl\"\n",
    "        with open(fpath, 'wb') as fobj:\n",
    "            pickle.dump(model_out, fobj)\n",
    "           \n",
    "    # return the accuracy lists so we can perform assessment \n",
    "    return accuracy_list, naive_accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list, naive_accuracy_list = train_xgb_models(data, pitch_count_cutoff=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five categories 2023 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pitchers that make the cut: 65\n",
      "\n",
      "Pitcher ID: 622491\n",
      "Pitcher's pitch map: {'MFastball': 0, 'Breaking Ball': 1, 'Off-Speed': 2, 'PFastball': 3}\n",
      "Pitcher's pitch counter: {'MFastball': 556, 'PFastball': 1408, 'Breaking Ball': 710, 'Off-Speed': 500}\n",
      "Number of data points in training: 2539\n",
      "Number of data points in testing: 635\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Total training time: 0:00:01.896866\n",
      "Naive accuracy: 44.4\n",
      "XGBooost accuracy: 80.6\n",
      "\n",
      "Pitcher ID: 605483\n",
      "Pitcher's pitch map: {'Breaking Ball': 0, 'Off-Speed': 1, 'PFastball': 2}\n",
      "Pitcher's pitch counter: {'Breaking Ball': 1042, 'PFastball': 1510, 'Off-Speed': 584}\n",
      "Number of data points in training: 2508\n",
      "Number of data points in testing: 628\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Total training time: 0:00:00.992865\n",
      "Naive accuracy: 48.2\n",
      "XGBooost accuracy: 94.9\n",
      "\n",
      "Pitcher ID: 669302\n",
      "Pitcher's pitch map: {'Breaking Ball': 0, 'PFastball': 1, 'MFastball': 2}\n",
      "Pitcher's pitch counter: {'PFastball': 1192, 'Breaking Ball': 1259, 'MFastball': 439}\n",
      "Number of data points in training: 2312\n",
      "Number of data points in testing: 578\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 20}\n",
      "Total training time: 0:00:01.239717\n",
      "Naive accuracy: 43.6\n",
      "XGBooost accuracy: 94.3\n",
      "\n",
      "Pitcher ID: 448179\n",
      "Pitcher's pitch map: {'Breaking Ball': 0, 'Off-Speed': 1, 'PFastball': 2, 'MFastball': 3}\n",
      "Pitcher's pitch counter: {'PFastball': 828, 'Breaking Ball': 1105, 'MFastball': 471, 'Off-Speed': 57}\n",
      "Number of data points in training: 1968\n",
      "Number of data points in testing: 493\n",
      "Best params: {'learning_rate': 0.4, 'max_depth': 2}\n",
      "Total training time: 0:00:00.934701\n",
      "Naive accuracy: 44.9\n",
      "XGBooost accuracy: 94.1\n",
      "\n",
      "Pitcher ID: 656756\n",
      "Pitcher's pitch map: {'MFastball': 0, 'Breaking Ball': 1, 'Off-Speed': 2, 'PFastball': 3}\n",
      "Pitcher's pitch counter: {'Off-Speed': 734, 'PFastball': 394, 'MFastball': 1427, 'Breaking Ball': 787}\n",
      "Number of data points in training: 2673\n",
      "Number of data points in testing: 669\n",
      "Best params: {'learning_rate': 0.4, 'max_depth': 2}\n",
      "Total training time: 0:00:01.604355\n",
      "Naive accuracy: 42.7\n",
      "XGBooost accuracy: 87.0\n",
      "\n",
      "Pitcher ID: 669194\n",
      "Pitcher's pitch map: {'Breaking Ball': 0, 'Off-Speed': 1, 'PFastball': 2, 'MFastball': 3}\n",
      "Pitcher's pitch counter: {'PFastball': 1334, 'Breaking Ball': 465, 'Off-Speed': 317, 'MFastball': 318}\n",
      "Number of data points in training: 1947\n",
      "Number of data points in testing: 487\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 2}\n",
      "Total training time: 0:00:00.982244\n",
      "Naive accuracy: 54.8\n",
      "XGBooost accuracy: 94.5\n",
      "\n",
      "Pitcher ID: 579328\n",
      "Pitcher's pitch map: {'Breaking Ball': 0, 'Off-Speed': 1, 'PFastball': 2}\n",
      "Pitcher's pitch counter: {'PFastball': 1245, 'Off-Speed': 271, 'Breaking Ball': 1286}\n",
      "Number of data points in training: 2241\n",
      "Number of data points in testing: 561\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 20}\n",
      "Total training time: 0:00:01.337432\n",
      "Naive accuracy: 45.9\n",
      "XGBooost accuracy: 94.5\n"
     ]
    }
   ],
   "source": [
    "accuracy_list, naive_accuracy_list = train_xgb_models(data2, pitch_count_cutoff=2400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five categories 2024 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv('../data/final/five_2024_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500605 entries, 0 to 500604\n",
      "Data columns (total 32 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   pitch_type                         500605 non-null  object \n",
      " 1   release_speed                      500605 non-null  float64\n",
      " 2   batter                             500605 non-null  int64  \n",
      " 3   pitcher                            500605 non-null  int64  \n",
      " 4   game_type                          500605 non-null  object \n",
      " 5   balls                              500605 non-null  int64  \n",
      " 6   strikes                            500605 non-null  int64  \n",
      " 7   on_3b                              500605 non-null  int64  \n",
      " 8   on_2b                              500605 non-null  int64  \n",
      " 9   on_1b                              500605 non-null  int64  \n",
      " 10  outs_when_up                       500605 non-null  int64  \n",
      " 11  inning                             500605 non-null  int64  \n",
      " 12  inning_topbot                      500605 non-null  object \n",
      " 13  at_bat_number                      500605 non-null  int64  \n",
      " 14  pitch_number                       500605 non-null  int64  \n",
      " 15  if_fielding_alignment              500605 non-null  object \n",
      " 16  of_fielding_alignment              500605 non-null  object \n",
      " 17  age_pit                            500605 non-null  int64  \n",
      " 18  age_bat                            500605 non-null  int64  \n",
      " 19  n_priorpa_thisgame_player_at_bat   500605 non-null  int64  \n",
      " 20  count                              500605 non-null  object \n",
      " 21  total_runners_on_base              500605 non-null  int64  \n",
      " 22  runners_in_scoring_position        500605 non-null  int64  \n",
      " 23  runners_in_scoring_position_2outs  500605 non-null  int64  \n",
      " 24  score_diff                         500605 non-null  int64  \n",
      " 25  month                              500605 non-null  int64  \n",
      " 26  stand_pitch_same_side              500605 non-null  int64  \n",
      " 27  game_pitcher_id                    500605 non-null  object \n",
      " 28  prev_pitch_type                    500605 non-null  object \n",
      " 29  prev_pitch_outcome                 489575 non-null  float64\n",
      " 30  prev_zone                          489575 non-null  float64\n",
      " 31  prev_pitch_velocity                500586 non-null  float64\n",
      "dtypes: float64(4), int64(20), object(8)\n",
      "memory usage: 122.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3[data3.pitch_type != 'Specialty']\n",
    "data3 = data3[data3.prev_pitch_type != 'Specialty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_models_2024(train_data, pitch_count_cutoff=1000):\n",
    "    '''\n",
    "    Function to train and test models for pitch prediction for individual pitchers\n",
    "    \n",
    "    train_data: a cleaned data frame\n",
    "    pitch_count_cutoff: a minimum number of pitches thrown  \n",
    "    \n",
    "    returns a pickled file for each pitcher that contains the model and some metadata for that pitcher\n",
    "    '''\n",
    "\n",
    "    # build a dict with pitch_id as key and total pitch count as value\n",
    "    pitcher_count_dict = dict(Counter(train_data['pitcher']))\n",
    "\n",
    "    # drop pitchers that don't have enough pitches to build a reliable model\n",
    "    pitcher_count_dict = {k:v for k, v in pitcher_count_dict.items() if v > pitch_count_cutoff}\n",
    "\n",
    "    # list of pitchers\n",
    "    pitcher_list = pitcher_count_dict.keys()\n",
    "    print(f\"Number of pitchers that make the cut: {len(pitcher_count_dict)}\")\n",
    "\n",
    "    # loop through the list of pitchers and train models\n",
    "    accuracy_list = []\n",
    "    naive_accuracy_list = []\n",
    "    num_skipped = 0\n",
    "    for i, pitcher in enumerate(pitcher_list):\n",
    "\n",
    "        # start a timer\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        df_pitcher = train_data[train_data['pitcher'] == pitcher]\n",
    "        df_pitcher.drop('pitcher', axis=1, inplace=True)\n",
    "\n",
    "        # get a unique list of the pitcher's pitches\n",
    "        pitch_types = list(set(list(df_pitcher['prev_pitch_type'].unique()) + list(df_pitcher['pitch_type'].unique())))\n",
    "        pitch_type_counts = Counter(df_pitcher['prev_pitch_type'])\n",
    "\n",
    "        # build maps for pitches to ints and ints back to pitches\n",
    "        pitch_map = {pitch_types[i]: i for i in range(len(pitch_types))}\n",
    "        pitch_unmap = {v: k for k, v in pitch_map.items()}\n",
    "\n",
    "        # map pitch types to ints\n",
    "        df_pitcher['pitch_type'] = df_pitcher['pitch_type'].apply(lambda x: pitch_map[x])\n",
    "        df_pitcher['prev_pitch_type'] = df_pitcher['prev_pitch_type'].apply(lambda x: pitch_map[x])\n",
    "\n",
    "        # split the dataframe into a feature set and an outcome column\n",
    "        X = df_pitcher.drop('pitch_type', axis=1)\n",
    "        y = df_pitcher['pitch_type']\n",
    "\n",
    "        # split the data into train/test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \"\"\"\n",
    "        if len(np.unique(y_train)) > len(np.unique(y_test)):\n",
    "            unique_classes = len(y_train.unique())\n",
    "        else:\n",
    "            unique_classes = len(y_test.unique())\n",
    "        \n",
    "        if len(np.unique(y_train)) > len(np.unique(y_test)):\n",
    "            # Get all unique classes from y_train\n",
    "            all_classes = np.unique(y_train)\n",
    "\n",
    "            # Align the test labels with the training classes\n",
    "            y_test = pd.Categorical(y_test, categories=all_classes).codes\n",
    "        else:\n",
    "            # Get all unique classes from y_test\n",
    "            all_classes = np.unique(y_test)\n",
    "\n",
    "            # Align the training labels with the test classes\n",
    "            y_train = pd.Categorical(y_train, categories=all_classes).codes\n",
    "        \"\"\"\n",
    "        # ----------------------\n",
    "        # train an XGBoost model\n",
    "        # ----------------------\n",
    "\n",
    "        # small set of hyperparameters to optimize over\n",
    "        xgb_params = {\"max_depth\": (2, 5, 20),\n",
    "                      \"learning_rate\": (0.01, 0.1, 0.4)}\n",
    "        \n",
    "        # perform the paramater grid search using 5-fold cross validation\n",
    "        xgb_opt = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=len(pitch_type_counts)), \n",
    "                               param_grid=xgb_params, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "        # perform fit and make predictions\n",
    "        xgb_opt.fit(X_train, y_train)\n",
    "        y_pred = xgb_opt.predict(X_test)\n",
    "        y_prob = xgb_opt.predict_proba(X_test)\n",
    "\n",
    "        # compute accuracy and store in a list for analyzing results later\n",
    "        accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        # get and store the naive accuracy (accuracy from just predicting the most thrown pitch)\n",
    "        naive_accuracy = round(max(pitch_type_counts.values()) / sum(pitch_type_counts.values()) * 100., 1)\n",
    "        naive_accuracy_list.append(naive_accuracy)\n",
    "\n",
    "        # print some input/results for every 10th pitcher\n",
    "        if i % 10 == 0:\n",
    "            print()\n",
    "            print(f\"Pitcher ID: {pitcher}\")\n",
    "            print(f\"Pitcher's pitch map: {pitch_map}\")\n",
    "            print(f\"Pitcher's pitch counter: {dict(pitch_type_counts)}\")\n",
    "            print(f\"Number of data points in training: {X_train.shape[0]}\")\n",
    "            print(f\"Number of data points in testing: {X_test.shape[0]}\")\n",
    "            print(f\"Best params: {xgb_opt.best_params_}\")\n",
    "            print(f\"Total training time: {dt.datetime.now()-start}\")\n",
    "            print(f\"Naive accuracy: {naive_accuracy}\")\n",
    "            print(f\"XGBooost accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "        # ----------------------------------------------------------\n",
    "        # write out the pitchers model and metadata to a pickle file\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "        # things to store in the pitcher's model file:\n",
    "        #  1) the map and unmap for pitches (used for data clean-up in the prediction process)\n",
    "        #  2) trained model (used to make prediction)\n",
    "        #  3) accuracy on the test data (to include with pitch predictions so user can see how confident the model is)\n",
    "        model_out = {\n",
    "            \"pitcherID\": pitcher,\n",
    "            \"pitch_map\": pitch_map,\n",
    "            \"pitch_unmap\": pitch_unmap,\n",
    "            \"model\": xgb_opt,\n",
    "            \"model_accuracy\": accuracy\n",
    "        }\n",
    "\n",
    "        # pickle up the pitcher's model file\n",
    "        fpath = \"../data/pitcher_models/2024/\" + str(pitcher) + \".pkl\"\n",
    "        with open(fpath, 'wb') as fobj:\n",
    "            pickle.dump(model_out, fobj)\n",
    "           \n",
    "    # return the accuracy lists so we can perform assessment \n",
    "    return accuracy_list, naive_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pitchers that make the cut: 74\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 2 3]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_list, naive_accuracy_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_xgb_models_2024\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpitch_count_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2400\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[223], line 83\u001b[0m, in \u001b[0;36mtrain_xgb_models_2024\u001b[0;34m(train_data, pitch_count_cutoff)\u001b[0m\n\u001b[1;32m     79\u001b[0m xgb_opt \u001b[38;5;241m=\u001b[39m GridSearchCV(XGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softprob\u001b[39m\u001b[38;5;124m'\u001b[39m, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(pitch_type_counts)), \n\u001b[1;32m     80\u001b[0m                        param_grid\u001b[38;5;241m=\u001b[39mxgb_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# perform fit and make predictions\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[43mxgb_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_opt\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     85\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m xgb_opt\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [0 2 3]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list, naive_accuracy_list = train_xgb_models_2024(data3, pitch_count_cutoff=2400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Encode target (pitch_type)\n",
    "target = 'pitch_type'\n",
    "features = [col for col in data.columns if col not in [target, 'pitcher']]  # Exclude 'pitcher' for looping\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data[target] = label_encoder.fit_transform(data[target])\n",
    "data['prev_pitch_type'] = label_encoder.fit_transform(data['prev_pitch_type'])\n",
    "\n",
    "def train_xgboost_with_gridsearch(data, target, features, min_pitches=0):\n",
    "    \"\"\"\n",
    "    Train XGBoost models with GridSearchCV for each pitcher above a certain number of pitches.\n",
    "    \n",
    "    Args:\n",
    "    - data (DataFrame): The full dataset.\n",
    "    - target (str): The target variable (e.g., 'pitch_type').\n",
    "    - features (list): List of feature columns.\n",
    "    - min_pitches (int): Minimum number of pitches required for a pitcher to be included.\n",
    "    \n",
    "    Returns:\n",
    "    - pitcher_results (list): List of dictionaries with results for each pitcher.\n",
    "    \"\"\"\n",
    "    # Filter pitchers based on the number of pitches\n",
    "    pitcher_counts = data['pitcher'].value_counts()\n",
    "    valid_pitchers = pitcher_counts[pitcher_counts >= min_pitches].index\n",
    "    filtered_data = data[data['pitcher'].isin(valid_pitchers)]\n",
    "    \n",
    "    pitcher_results = []\n",
    "    for pitcher_id in filtered_data['pitcher'].unique():\n",
    "        print(f\"\\nProcessing pitcher: {pitcher_id}\")\n",
    "        \n",
    "        # Filter data for the current pitcher\n",
    "        pitcher_data = filtered_data[filtered_data['pitcher'] == pitcher_id]\n",
    "        \n",
    "        # Split data into train and test\n",
    "        X = pitcher_data[features]\n",
    "        y = pitcher_data[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        unique_classes_in_test = np.unique(y_test)\n",
    "        \n",
    "        # Define the pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Feature scaling\n",
    "            ('xgb', XGBClassifier(eval_metric='mlogloss'))  # XGBoost model\n",
    "        ])\n",
    "        \n",
    "        # Define the hyperparameter grid\n",
    "        param_grid = {\n",
    "            'xgb__n_estimators': [50, 100, 150],\n",
    "            'xgb__max_depth': [3, 5, 7],\n",
    "            'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'xgb__subsample': [0.8, 1.0],\n",
    "            'xgb__colsample_bytree': [0.8, 1.0],\n",
    "        }\n",
    "        \n",
    "        # GridSearchCV\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Best parameters and performance\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Best Params for Pitcher {pitcher_id}: {best_params}\")\n",
    "        \n",
    "        # Evaluate the best model on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        target_names = [str(cls) for cls in label_encoder.classes_[unique_classes_in_test]]\n",
    "        report = classification_report(y_test, y_pred, target_names=target_names, labels=unique_classes_in_test, zero_division=0)\n",
    "        print(report)\n",
    "        \n",
    "        # Append results\n",
    "        pitcher_results.append({\n",
    "            'pitcher_id': pitcher_id,\n",
    "            'num_pitches': len(pitcher_data),\n",
    "            'best_params': best_params,\n",
    "            'classification_report': report\n",
    "        })\n",
    "    \n",
    "    return pitcher_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_xgboost_with_gridsearch(data, target, features, min_pitches=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
