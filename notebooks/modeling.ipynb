{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re \n",
    "import ast \n",
    "import json \n",
    "import pickle \n",
    "from collections import Counter \n",
    "import datetime as dt\n",
    "import pybaseball\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pybaseball import pitching_stats_bref\n",
    "from pybaseball import statcast\n",
    "from pybaseball import statcast_pitcher\n",
    "from pybaseball import playerid_lookup\n",
    "from pybaseball import playerid_reverse_lookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost\n",
    "- Random Forest\n",
    "- RNN (LSTM or GRU or both)\n",
    "\n",
    "RNN will likely take too long depending on how the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/final/pitch_by_pitch_2023_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503292 entries, 0 to 503291\n",
      "Data columns (total 33 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   pitch_type                         503292 non-null  object \n",
      " 1   release_speed                      503292 non-null  float64\n",
      " 2   batter                             503292 non-null  int64  \n",
      " 3   pitcher                            503292 non-null  int64  \n",
      " 4   game_type                          503292 non-null  object \n",
      " 5   balls                              503292 non-null  int64  \n",
      " 6   strikes                            503292 non-null  int64  \n",
      " 7   on_3b                              503292 non-null  int64  \n",
      " 8   on_2b                              503292 non-null  int64  \n",
      " 9   on_1b                              503292 non-null  int64  \n",
      " 10  outs_when_up                       503292 non-null  int64  \n",
      " 11  inning                             503292 non-null  int64  \n",
      " 12  inning_topbot                      503292 non-null  object \n",
      " 13  at_bat_number                      503292 non-null  int64  \n",
      " 14  pitch_number                       503292 non-null  int64  \n",
      " 15  if_fielding_alignment              503292 non-null  object \n",
      " 16  of_fielding_alignment              503292 non-null  object \n",
      " 17  age_pit                            503292 non-null  int64  \n",
      " 18  age_bat                            503292 non-null  int64  \n",
      " 19  n_priorpa_thisgame_player_at_bat   503292 non-null  int64  \n",
      " 20  count                              503292 non-null  object \n",
      " 21  total_runners_on_base              503292 non-null  int64  \n",
      " 22  runners_in_scoring_position        503292 non-null  int64  \n",
      " 23  runners_in_scoring_position_2outs  503292 non-null  int64  \n",
      " 24  score_diff                         503292 non-null  int64  \n",
      " 25  month                              503292 non-null  int64  \n",
      " 26  stand_pitch_same_side              503292 non-null  int64  \n",
      " 27  game_pitcher_id                    503292 non-null  object \n",
      " 28  prev_pitch_type                    503292 non-null  object \n",
      " 29  prev_pitch_outcome                 492550 non-null  float64\n",
      " 30  prev_zone                          492550 non-null  float64\n",
      " 31  prev_pitch_velocity                503280 non-null  float64\n",
      " 32  pitch_category                     503260 non-null  object \n",
      "dtypes: float64(4), int64(20), object(9)\n",
      "memory usage: 126.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['pitch_category', 'game_type', 'inning_topbot', 'if_fielding_alignment', 'of_fielding_alignment', 'count', 'game_pitcher_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prev_pitch_type'] = data['prev_pitch_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503287    ST\n",
       "503288    FF\n",
       "503289    FF\n",
       "503290    ST\n",
       "503291    UN\n",
       "Name: prev_pitch_type, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prev_pitch_type'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_models(train_data, pitch_count_cutoff=1000):\n",
    "    '''\n",
    "    Function to train and test models for pitch prediction for individual pitchers\n",
    "    \n",
    "    train_data: a cleaned data frame\n",
    "    pitch_count_cutoff: a minimum number of pitches thrown  \n",
    "    \n",
    "    returns a pickled file for each pitcher that contains the model and some metadata for that pitcher\n",
    "    '''\n",
    "\n",
    "    # build a dict with pitch_id as key and total pitch count as value\n",
    "    pitcher_count_dict = dict(Counter(train_data['pitcher']))\n",
    "\n",
    "    # drop pitchers that don't have enough pitches to build a reliable model\n",
    "    pitcher_count_dict = {k:v for k, v in pitcher_count_dict.items() if v > pitch_count_cutoff}\n",
    "\n",
    "    # list of pitchers\n",
    "    pitcher_list = pitcher_count_dict.keys()\n",
    "    print(f\"Number of pitchers that make the cut: {len(pitcher_count_dict)}\")\n",
    "\n",
    "    # loop through the list of pitchers and train models\n",
    "    accuracy_list = []\n",
    "    naive_accuracy_list = []\n",
    "    num_skipped = 0\n",
    "    for i, pitcher in enumerate(pitcher_list):\n",
    "\n",
    "        # start a timer\n",
    "        start = dt.datetime.now()\n",
    "\n",
    "        df_pitcher = train_data[train_data['pitcher'] == pitcher]\n",
    "        df_pitcher.drop('pitcher', axis=1, inplace=True)\n",
    "\n",
    "        # get a unique list of the pitcher's pitches\n",
    "        pitch_types = list(set(list(df_pitcher['prev_pitch_type'].unique()) + list(df_pitcher['pitch_type'].unique())))\n",
    "        pitch_type_counts = Counter(df_pitcher['pitch_type'])\n",
    "\n",
    "        # build maps for pitches to ints and ints back to pitches\n",
    "        pitch_map = {pitch_types[i]: i for i in range(len(pitch_types))}\n",
    "        pitch_unmap = {v: k for k, v in pitch_map.items()}\n",
    "\n",
    "        # map pitch types to ints\n",
    "        df_pitcher['pitch_type'] = df_pitcher['pitch_type'].apply(lambda x: pitch_map[x])\n",
    "        df_pitcher['prev_pitch_type'] = df_pitcher['prev_pitch_type'].apply(lambda x: pitch_map[x])\n",
    "\n",
    "        # split the dataframe into a feature set and an outcome column\n",
    "        X = df_pitcher.drop('pitch_type', axis=1)\n",
    "        y = df_pitcher['pitch_type']\n",
    "\n",
    "        # split the data into train/test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # ----------------------\n",
    "        # train an XGBoost model\n",
    "        # ----------------------\n",
    "\n",
    "        # small set of hyperparameters to optimize over\n",
    "        xgb_params = {\"max_depth\": (2, 5, 20),\n",
    "                      \"learning_rate\": (0.01, 0.1, 0.4)}\n",
    "\n",
    "        # perform the paramater grid search using 5-fold cross validation\n",
    "        xgb_opt = GridSearchCV(XGBClassifier(objective='multi:softprob', num_class=len(pitch_type_counts)), \n",
    "                               param_grid=xgb_params, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "\n",
    "        # perform fit and make predictions\n",
    "        xgb_opt.fit(X_train, y_train)\n",
    "        y_pred = xgb_opt.predict(X_test)\n",
    "        y_prob = xgb_opt.predict_proba(X_test)\n",
    "\n",
    "        # compute accuracy and store in a list for analyzing results later\n",
    "        accuracy = round(accuracy_score(y_test, y_pred) * 100, 1)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "        # get and store the naive accuracy (accuracy from just predicting the most thrown pitch)\n",
    "        naive_accuracy = round(max(pitch_type_counts.values()) / sum(pitch_type_counts.values()) * 100., 1)\n",
    "        naive_accuracy_list.append(naive_accuracy)\n",
    "\n",
    "        # print some input/results for every 10th pitcher\n",
    "        if i % 10 == 0:\n",
    "            print()\n",
    "            print(f\"Pitcher ID: {pitcher}\")\n",
    "            print(f\"Pitcher's pitch map: {pitch_map}\")\n",
    "            print(f\"Pitcher's pitch counter: {dict(pitch_type_counts)}\")\n",
    "            print(f\"Number of data points in training: {X_train.shape[0]}\")\n",
    "            print(f\"Number of data points in testing: {X_test.shape[0]}\")\n",
    "            print(f\"Best params: {xgb_opt.best_params_}\")\n",
    "            print(f\"Total training time: {dt.datetime.now()-start}\")\n",
    "            print(f\"Naive accuracy: {naive_accuracy}\")\n",
    "            print(f\"XGBooost accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "        # ----------------------------------------------------------\n",
    "        # write out the pitchers model and metadata to a pickle file\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "        # things to store in the pitcher's model file:\n",
    "        #  1) the map and unmap for pitches (used for data clean-up in the prediction process)\n",
    "        #  2) trained model (used to make prediction)\n",
    "        #  3) accuracy on the test data (to include with pitch predictions so user can see how confident the model is)\n",
    "        model_out = {\n",
    "            \"pitcherID\": pitcher,\n",
    "            \"pitch_map\": pitch_map,\n",
    "            \"pitch_unmap\": pitch_unmap,\n",
    "            \"model\": xgb_opt,\n",
    "            \"model_accuracy\": accuracy\n",
    "        }\n",
    "\n",
    "        # pickle up the pitcher's model file\n",
    "        fpath = \"../data/pitcher_models/\" + str(pitcher) + \".pkl\"\n",
    "        with open(fpath, 'wb') as fobj:\n",
    "            pickle.dump(model_out, fobj)\n",
    "           \n",
    "    # return the accuracy lists so we can perform assessment \n",
    "    return accuracy_list, naive_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pitchers that make the cut: 100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 1 3 4]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_list, naive_accuracy_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_xgb_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpitch_count_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 65\u001b[0m, in \u001b[0;36mtrain_xgb_models\u001b[0;34m(train_data, pitch_count_cutoff)\u001b[0m\n\u001b[1;32m     61\u001b[0m xgb_opt \u001b[38;5;241m=\u001b[39m GridSearchCV(XGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softprob\u001b[39m\u001b[38;5;124m'\u001b[39m, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(pitch_type_counts)), \n\u001b[1;32m     62\u001b[0m                        param_grid\u001b[38;5;241m=\u001b[39mxgb_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# perform fit and make predictions\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[43mxgb_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_opt\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     67\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m xgb_opt\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list, naive_accuracy_list = train_xgb_models(data, pitch_count_cutoff=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
